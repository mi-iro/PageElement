import argparse
import os
import sys
import torch
import asyncio

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­ï¼Œä»¥ä¾¿å¯¼å…¥ src æ¨¡å—
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from src.agents.AgenticRAGAgent import AgenticRAGAgent
from src.agents.ElementExtractor import ElementExtractor
from src.agents.utils import ImageZoomOCRTool
from src.loaders.MMLongLoader import MMLongLoader
from src.loaders.FinRAGLoader import FinRAGLoader
from src.utils.llm_helper import create_llm_caller

try:
    from scripts.qwen3_vl_embedding import Qwen3VLEmbedder
    from scripts.qwen3_vl_reranker import Qwen3VLReranker
except ImportError:
    print("Warning: Qwen3 VL scripts not found.")

def parse_args():
    parser = argparse.ArgumentParser(description="Run AgenticRAGAgent benchmark evaluation.")

    # åŸºç¡€é…ç½®
    parser.add_argument("--benchmark", type=str, default="mmlong", choices=["mmlong", "finrag"], help="Target benchmark to run.")
    parser.add_argument("--data_root", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/PageElement/MMLongBench-Doc", help="Path to the dataset root directory.")
    parser.add_argument("--output_dir", type=str, default="./results_mmlong", help="Directory to save results and cache.")
    
    # LLM é…ç½® (Main Agent ä½¿ç”¨)
    parser.add_argument("--model_name", type=str, default="qwen3-max", help="LLM model name (e.g., qwen3-max).")
    parser.add_argument("--base_url", type=str, default="http://localhost:3888/v1", help="LLM API Base URL.")
    parser.add_argument("--api_key", type=str, default="sk-6TGzZJkJ5HfZKwnrS1A1pMb1lH5D7EDfSVC6USq24aN2JaaR", help="LLM API Key.")
    
    # Agent é…ç½®
    parser.add_argument("--max_rounds", type=int, default=5, help="Maximum thinking rounds for AgenticRAGAgent.")
    parser.add_argument("--limit", type=int, default=5, help="Limit the number of samples for testing (e.g., 10).")

    # æ¨¡å‹è·¯å¾„é…ç½® (æ ¹æ® Benchmark éœ€æ±‚)
    parser.add_argument("--embedding_model", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/JIT-RAG/assets/Qwen/Qwen3-VL-Embedding-8B", help="Path to Qwen3-VL-Embedding model (Required for FinRAG).")
    parser.add_argument("--reranker_model", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/JIT-RAG/assets/Qwen/Qwen3-VL-Reranker-8B", help="Path to Qwen3-VL-Reranker model.")
    
    # MinerU / OCR é…ç½®
    parser.add_argument("--mineru_server_url", type=str, default="http://10.102.250.36:8000/", help="MinerU API Server URL.")
    parser.add_argument("--mineru_model_path", type=str, default="/root/checkpoints/MinerU2.5-2509-1.2B/", help="MinerU Model Path.")
    
    # ElementExtractor é…ç½®
    parser.add_argument("--extractor_model_name", type=str, default="MinerU-Agent-CK300", help="LLM model name (e.g., qwen3-max).")
    parser.add_argument("--extractor_base_url", type=str, default="http://localhost:8001/v1", help="LLM API Base URL.")
    parser.add_argument("--extractor_api_key", type=str, default="sk-123456", help="LLM API Key.")

    # FinRAG ç‰¹æœ‰é…ç½®
    parser.add_argument("--finrag_lang", type=str, default="ch", choices=["ch", "en", "bbox"], help="Language/subset for FinRAG.")
    parser.add_argument("--force_rebuild_index", action="store_true", help="Force rebuild vector index for FinRAG.")

    return parser.parse_args()

def main():
    args = parse_args()

    # 1. ç›®å½•å‡†å¤‡
    os.makedirs(args.output_dir, exist_ok=True)
    workspace_dir = os.path.join(args.output_dir, "workspace")
    cache_dir = os.path.join(args.output_dir, "cache")
    os.makedirs(workspace_dir, exist_ok=True)
    os.makedirs(cache_dir, exist_ok=True)

    print(f"ğŸš€ Starting Benchmark: {args.benchmark.upper()}")
    print(f"ğŸ“‚ Data Root: {args.data_root}")
    print(f"ğŸ’¾ Output Dir: {args.output_dir}")

    # 2. åˆå§‹åŒ–åº•å±‚å·¥å…·ä¸æå–å™¨ (ElementExtractor)
    print("ğŸ› ï¸ Initializing Tools and Extractor...")
    tool = ImageZoomOCRTool(
        work_dir=os.path.join(workspace_dir, "crops"),
        mineru_server_url=args.mineru_server_url,
        mineru_model_path=args.mineru_model_path
    )
    
    # æ³¨æ„ï¼šExtractor é€šå¸¸ä½¿ç”¨ Vision æ¨¡å‹ (å¦‚ qwen-vl-max æˆ– qwen3-vl-instruct)
    # è¿™é‡Œå¤ç”¨ args.base_urlï¼Œä½†ä½ å¯ä»¥æ ¹æ®éœ€è¦åˆ†ç¦» Extractor çš„ LLM é…ç½®
    extractor = ElementExtractor(
        base_url=args.extractor_base_url,
        api_key=args.extractor_api_key,
        model_name=args.extractor_model_name,
        tool=tool
    )

    loader = None

    # 3. åˆå§‹åŒ– DataLoader
    if args.benchmark == "mmlong":
        print("ğŸ“¥ Loading MMLongLoader...")
        loader = MMLongLoader(
            data_root=args.data_root, 
            extractor=extractor,
            reranker_model_path=args.reranker_model
        )
        loader.load_data()

    elif args.benchmark == "finrag":
        print("ğŸ“¥ Loading FinRAGLoader...")
        if not args.embedding_model or not args.reranker_model:
            raise ValueError("FinRAG benchmark requires --embedding_model and --reranker_model.")
        
        # åŠ è½½æœ¬åœ°æ¨¡å‹
        print("   Loading Embedding Model (this may take time)...")
        embedder = Qwen3VLEmbedder(model_name_or_path=args.embedding_model, torch_dtype=torch.float16)
        print("   Loading Reranker Model...")
        reranker = Qwen3VLReranker(model_name_or_path=args.reranker_model, torch_dtype=torch.float16)

        loader = FinRAGLoader(
            data_root=args.data_root,
            lang=args.finrag_lang,
            embedding_model=embedder,
            rerank_model=reranker,
            extractor=extractor
        )
        loader.load_data()
        
        # å»ºç«‹æˆ–åŠ è½½ç´¢å¼•
        loader.build_page_vector_pool(batch_size=4, force_rebuild=args.force_rebuild_index)

    # è®¾ç½®ç”¨äºè¯„ä¼°çš„ LLM Helper
    loader.llm_caller = create_llm_caller()

    # 4. æˆªå–æµ‹è¯•æ ·æœ¬ (å¦‚æœè®¾ç½®äº† limit)
    if args.limit and args.limit > 0:
        print(f"âš ï¸ Limiting samples to {args.limit} for testing.")
        loader.samples = loader.samples[:args.limit]

    print(f"ğŸ“Š Total Samples to Process: {len(loader.samples)}")

    # 5. åˆå§‹åŒ– Agentic RAG Agent
    agent = AgenticRAGAgent(
        loader=loader,
        base_url=args.base_url,
        api_key=args.api_key,
        model_name=args.model_name,
        max_rounds=args.max_rounds,
        cache_dir=cache_dir
    )

    # 6. æ‰§è¡Œå¤„ç†å¾ªç¯
    print("\nâš¡ Starting Processing Loop...")
    for i, sample in enumerate(loader.samples):
        print(f"[{i+1}/{len(loader.samples)}] Processing Sample QID: {sample.qid}")
        agent.process_sample(sample)

    # 7. ä¿å­˜ç»“æœ
    excel_path = os.path.join(args.output_dir, f"{args.benchmark}_results.xlsx")
    json_path = os.path.join(args.output_dir, f"{args.benchmark}_results.json")
    agent.save_results(excel_path=excel_path, json_path=json_path)

    # 8. æ‰§è¡Œè¯„ä¼°
    print("\nğŸ“ˆ Starting Evaluation...")
    try:
        metrics = loader.evaluate()
        # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
        metrics_path = os.path.join(args.output_dir, "evaluation_metrics.json")
        with open(metrics_path, "w", encoding="utf-8") as f:
            import json
            json.dump(metrics, f, indent=2)
        print(f"âœ… Evaluation complete. Metrics saved to {metrics_path}")
    except Exception as e:
        print(f"âŒ Evaluation failed: {e}")

if __name__ == "__main__":
    main()