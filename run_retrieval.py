# run_retrieval.py
import json
import os
import time
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from bootstrap import parse_args, initialize_components, save_run_config

def process_single_sample_retrieval(sample, agent, cache_dir):
    """
    å•ä¸ªæ ·æœ¬çš„æ£€ç´¢å¤„ç†å‡½æ•°ï¼Œæ”¯æŒç¼“å­˜è¯»å–
    """
    qid = str(sample.qid)
    # å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢æ–‡ä»¶åéæ³•
    safe_qid = "".join([c if c.isalnum() else "_" for c in qid])
    cache_path = os.path.join(cache_dir, f"{safe_qid}.json")

    # 1. Check Cache
    if os.path.exists(cache_path):
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass # Cache corrupted, re-run

    # 2. Run Retrieval
    try:
        elements = agent.retrieve(sample)
        # åºåˆ—åŒ–
        elements_data = [el.to_dict() if hasattr(el, 'to_dict') else el for el in elements]
    except Exception as e:
        print(f"Error retrieving sample {qid}: {e}")
        elements_data = []

    result_item = {
        "qid": sample.qid,
        "query": sample.query,
        "gold_answer": sample.gold_answer,
        "data_source": sample.data_source,
        "gold_pages": getattr(sample, 'gold_pages', []),
        "retrieved_elements": elements_data
    }

    # 3. Save Cache
    try:
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump(result_item, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving cache for {qid}: {e}")

    return result_item

def main():
    args = parse_args()
    save_run_config(args, "retrieval")
    print(f"ğŸš€ Starting Retrieval Stage for {args.benchmark} (Threads: {args.num_threads})...")
    
    # åˆå§‹åŒ–ç»„ä»¶
    agent, loader = initialize_components(args, init_retriever=True, init_generator=False)
    
    # å‡†å¤‡ç¼“å­˜ç›®å½•
    cache_dir = os.path.join(args.output_dir, "cache_retrieval_results")
    os.makedirs(cache_dir, exist_ok=True)
    print(f"ğŸ“‚ Cache directory: {cache_dir}")

    retrieval_results = []
    samples = loader.samples
    print(f"Processing {len(samples)} samples...")

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=args.num_threads) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_qid = {
            executor.submit(process_single_sample_retrieval, sample, agent, cache_dir): sample.qid 
            for sample in samples
        }
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        for future in tqdm(as_completed(future_to_qid), total=len(samples), desc="Retrieving"):
            try:
                result = future.result()
                if result:
                    retrieval_results.append(result)
            except Exception as e:
                print(f"Thread exception: {e}")

    # æ’åºä»¥ä¿æŒé¡ºåºä¸€è‡´æ€§ (å¤šçº¿ç¨‹è¿”å›é¡ºåºæ˜¯ä¹±çš„)
    # æ ¹æ® qid æ’åºï¼Œå¦‚æœ qid ä¸æ˜¯æ•°å­—ï¼Œåˆ™æŒ‰å­—ç¬¦ä¸²æ’åº
    try:
        retrieval_results.sort(key=lambda x: int(x['qid']) if str(x['qid']).isdigit() else str(x['qid']))
    except:
        pass # Fallback if mixed types

    # ä¿å­˜æœ€ç»ˆæ±‡æ€»ç»“æœ
    output_file = os.path.join(args.output_dir, "retrieval_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(retrieval_results, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Retrieval complete. Results saved to {output_file}")

if __name__ == "__main__":
    main()